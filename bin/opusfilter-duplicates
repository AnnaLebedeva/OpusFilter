#!/usr/bin/env python3

import argparse
import collections
import logging
from yaml import load, Loader

from tqdm import tqdm

from opusfilter.segment_hash import SegmentHasher
from opusfilter.util import file_open

logger = logging.getLogger(__name__)

logging.basicConfig(level=logging.INFO)
logging.getLogger('mosestokenizer.tokenizer.MosesTokenizer').setLevel(logging.WARNING)

parser = argparse.ArgumentParser(prog='opusfilter-duplicates',
    description='find duplicates from parallel text data using hashes and print statistics')

parser.add_argument('files', nargs='+', help='parallel text input files')
parser.add_argument('--compare', type=str, default='all',
                    help=('comma-separated indices for selecting the '
                          'segments to hash (e.g. "0,2") or "all" (default)'))
parser.add_argument('--hash', type=str, default='xx_64',
                    help=('hash function from pyhash library, empty string '
                          'for no hashing (default "xx_64")'))
parser.add_argument('--letters-only', action='store_true', default=False,
                    help='lowercase input strings before hashing')
parser.add_argument('--lowercase', action='store_true', default=False,
                    help='remove all non-letters from intput strings before hashing')

args = parser.parse_args()

hasher = SegmentHasher(
    compare=args.compare if args.compare == 'all' else [int(x) for x in args.compare.split(',')],
    hash=args.hash,
    letters_only=args.letters_only,
    lowercase=args.lowercase
)

infs = [file_open(infile) for infile in args.files]
counter = collections.Counter()
removed_entries = 0
total = 0
for lines in tqdm(zip(*infs)):
    total += 1
    key = hasher.apply(lines)
    counter[key] += 1

counts_of_counts = collections.Counter(counter.values())
logger.debug(counts_of_counts)

print("Total segment pairs: {}".format(total))
print("Unique segment pairs: {}".format(sum(counts_of_counts.values())))
print("Segment pairs occurring once: {}".format(counts_of_counts[1]))
print("Average number of duplicates: {:.1f}".format(
    sum((k * v) for k, v in counts_of_counts.items()) / sum(counts_of_counts.values())))
print("Max number of duplicates: {}".format(max(counts_of_counts.keys())))
